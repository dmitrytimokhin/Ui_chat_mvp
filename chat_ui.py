import streamlit as st
import requests
from datetime import datetime

FASTAPI_URL = "http://localhost:8000"

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

st.sidebar.title("üß† LLM –ß–∞—Ç")
page = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", ["–û –ø—Ä–æ–µ–∫—Ç–µ", "–ß–∞—Ç", "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞"], index=0)

if page == "–û –ø—Ä–æ–µ–∫—Ç–µ":
    st.title("üìñ –û –ø—Ä–æ–µ–∫—Ç–µ")
    st.markdown("""
    ### üß† –ì–∏–±—Ä–∏–¥–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π LLM-—á–∞—Ç

    - **phi3_ollama**: —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—ã–π Ollama (–±—ã—Å—Ç—Ä–æ).
    - **qwen_vllm**: —á–µ—Ä–µ–∑ vLLM (CPU) —Å –º–æ–¥–µ–ª—å—é Qwen3-4B (–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–æ –º–æ—â–Ω–æ).
    - –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ—Å—Ç–∞—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ.
    - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Streamlit ‚Üí FastAPI ‚Üí vLLM/Ollama.
    """)

elif page == "–ß–∞—Ç":
    st.title("üí¨ –ß–∞—Ç —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM")
    model_choice = st.sidebar.selectbox("–ú–æ–¥–µ–ª—å:", ["ollama", "Qwen3"], index=0)
    # –ï—Å–ª–∏ –≤—ã–±—Ä–∞–ª–∏ ollama ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç (phi / qwen_lite / qwen_pro)
    ollama_variant = None
    if model_choice == "ollama":
        ollama_variant = st.sidebar.selectbox("Ollama –º–æ–¥–µ–ª—å:", ["phi", "qwen_lite", "qwen_pro"], index=0)

    temperature = st.sidebar.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 0.0, 1.0, 0.0, 0.1)
    # –ß–∏—Å–ª–æ–≤–æ–π –≤–≤–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤ (—Ü–µ–ª–æ–µ —á–∏—Å–ª–æ)
    max_tokens_response = int(st.sidebar.number_input("–ú–∞–∫—Å. —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç–≤–µ—Ç–∞", min_value=1, max_value=4096, value=512, step=1))

    if st.sidebar.button("üóëÔ∏è –°–±—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ª–æ–≥"):
        st.session_state.chat_history = []
        st.rerun()

    if prompt := st.chat_input("–í–∞—à –≤–æ–ø—Ä–æ—Å..."):
        st.session_state.chat_history.append({"role": "user", "text": prompt})
        payload = {
            "prompt": prompt,
            "history": st.session_state.chat_history[:-1],
            "model_alias": model_choice,
            "ollama_model": ollama_variant,
            "temperature": temperature,
            "max_tokens": max_tokens_response
        }

        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
            try:
                # Qwen on CPU can be slow; increase timeout to 10 minutes
                resp = requests.post(f"{FASTAPI_URL}/chat", json=payload, timeout=600)
                if resp.status_code == 200:
                    data = resp.json()
                    response = data.get("response", "") or f"‚ùå –û—à–∏–±–∫–∞: {data.get('error', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
                else:
                    response = f"‚ùå –û—à–∏–±–∫–∞ API: {resp.status_code}"
            except Exception as e:
                response = f"‚ùå –ù–µ—Ç —Å–≤—è–∑–∏ —Å –±—ç–∫–µ–Ω–¥–æ–º: {str(e)}"
        st.session_state.chat_history.append({"role": "assistant", "text": response})

    for msg in st.session_state.chat_history[-30:]:
        with st.chat_message(msg["role"]):
            st.write(msg["text"])
    extra = f" (variant={ollama_variant})" if ollama_variant else ""
    st.caption(f"–ú–æ–¥–µ–ª—å: {model_choice}{extra} | –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temperature}")

elif page == "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞":
    st.title("üìú –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞")
    if not st.session_state.chat_history:
        st.info("–î–∏–∞–ª–æ–≥ –ø—É—Å—Ç.")
    else:
        for msg in st.session_state.chat_history:
            role_emoji = "üë§" if msg["role"] == "user" else "ü§ñ"
            st.markdown(f"**{role_emoji} {msg['role'].title()}:** {msg['text']}")
        history_text = "\n".join(
            f"[{'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å' if m['role'] == 'user' else '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç'}]: {m['text']}"
            for m in st.session_state.chat_history
        )
        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –≤ TXT",
            history_text,
            f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            "text/plain"
        )